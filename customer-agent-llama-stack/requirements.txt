# Requirements for llama_stack_agent_responses.py
# Llama Stack agent responses standalone script

# Core dependencies
llama-stack-client==0.3.1
python-dotenv==1.2.1

# MCP Server dependencies
fastmcp
httpx
mcp

# LangGraph dependencies
langgraph>=0.2.0
langchain-core>=0.3.0
langchain-ollama>=0.2.0
langchain>=0.3.0
requests>=2.32.0

# Testing dependencies (optional)
pytest
pytest-asyncio
