# source setenv.sh
export LLAMA_STACK_BASE_URL=http://localhost:8321
export INFERENCE_MODEL=ollama/llama3.2:3b